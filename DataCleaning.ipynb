{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc4724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/14 00:57:07 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/12/14 00:57:07 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/12/14 00:57:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/12/14 00:57:07 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Data Cleaning\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5789e4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/14 00:57:38 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:57:53 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:58:08 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:58:23 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:58:38 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:58:53 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:59:08 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:59:23 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:59:38 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 00:59:53 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 01:00:08 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 01:00:23 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 01:00:38 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 01:00:53 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/12/14 01:02:34 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n",
      "|               legId|searchDate|flightDate|startingAirport|destinationAirport|fareBasisCode|travelDuration|elapsedDays|isBasicEconomy|isRefundable|isNonStop|baseFare|totalFare|seatsRemaining|totalTravelDistance|segmentsDepartureTimeEpochSeconds|segmentsDepartureTimeRaw|segmentsArrivalTimeEpochSeconds|segmentsArrivalTimeRaw|segmentsArrivalAirportCode|segmentsDepartureAirportCode|segmentsAirlineName|segmentsAirlineCode|segmentsEquipmentDescription|segmentsDurationInSeconds|segmentsDistance|segmentsCabinCode|\n",
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n",
      "|9ca0e81111c683bec...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H29M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650214620|    2022-04-17T12:57:...|                     1650223560|  2022-04-17T15:26:...|                       BOS|                         ATL|              Delta|                 DL|                 Airbus A321|                     8940|             947|            coach|\n",
      "|98685953630e772a0...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H30M|          0|         false|       false|     true|  217.67|    248.6|             4|                947|                       1650191400|    2022-04-17T06:30:...|                     1650200400|  2022-04-17T09:00:...|                       BOS|                         ATL|              Delta|                 DL|                 Airbus A321|                     9000|             947|            coach|\n",
      "|98d90cbc32bfbb05c...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H30M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650209700|    2022-04-17T11:35:...|                     1650218700|  2022-04-17T14:05:...|                       BOS|                         ATL|              Delta|                 DL|              Boeing 757-200|                     9000|             947|            coach|\n",
      "|969a269d38eae583f...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H32M|          0|         false|       false|     true|  217.67|    248.6|             8|                947|                       1650218340|    2022-04-17T13:59:...|                     1650227460|  2022-04-17T16:31:...|                       BOS|                         ATL|              Delta|                 DL|                 Airbus A321|                     9120|             947|            coach|\n",
      "|980370cf27c89b40d...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H34M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650203940|    2022-04-17T09:59:...|                     1650213180|  2022-04-17T12:33:...|                       BOS|                         ATL|              Delta|                 DL|                 Airbus A321|                     9240|             947|            coach|\n",
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = \"gs://my-bigdatatech-project-jl/landing/itineraries.csv\"\n",
    "df_cleaned = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624dfeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:======================================================> (41 + 1) / 42]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+-----+\n",
      "|legId|searchDate|flightDate|startingAirport|destinationAirport|fareBasisCode|travelDuration|elapsedDays|isBasicEconomy|isRefundable|isNonStop|baseFare|totalFare|seatsRemaining|totalTravelDistance|segmentsDepartureTimeEpochSeconds|segmentsDepartureTimeRaw|segmentsArrivalTimeEpochSeconds|segmentsArrivalTimeRaw|segmentsArrivalAirportCode|segmentsDepartureAirportCode|segmentsAirlineName|segmentsAirlineCode|segmentsEquipmentDescription|segmentsDurationInSeconds|segmentsDistance|segmentsCabinCode|count|\n",
      "+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+-----+\n",
      "+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# group by all columns and count occurrences\n",
    "duplicates = df_cleaned.groupBy(df_cleaned.columns).count().filter(\"count > 1\")\n",
    "duplicates.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09511354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================================================>(124 + 1) / 125]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in segmentsEquipmentDescription: 883152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# count nulls in a column\n",
    "def count_nulls(df, column_name):\n",
    "    return df.select(\n",
    "        when(col(column_name).isNull(), 1).alias(column_name)\n",
    "    ).groupBy().sum(column_name).collect()[0][0]\n",
    "\n",
    "null_count = count_nulls(df_cleaned, \"segmentsEquipmentDescription\")\n",
    "print(f\"Number of null values in segmentsEquipmentDescription: {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c32953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "# impute `totalTravelDistance` with mean\n",
    "\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "mean_value = df_cleaned.select(mean(\"totalTravelDistance\")).collect()[0][0]\n",
    "df_cleaned = df_cleaned.fillna({\"totalTravelDistance\": mean_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc20873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------+\n",
      "|totalTravelDistance|segmentsEquipmentDescription|\n",
      "+-------------------+----------------------------+\n",
      "|                947|                 Airbus A321|\n",
      "|                947|                 Airbus A321|\n",
      "|                947|              Boeing 757-200|\n",
      "|                947|                 Airbus A321|\n",
      "|                947|                 Airbus A321|\n",
      "|                947|              Boeing 737-800|\n",
      "|                956|        Airbus A320||Airb...|\n",
      "|                956|        Airbus A320||Boei...|\n",
      "|                956|        Airbus A319||Airb...|\n",
      "|                956|        Airbus A319||Boei...|\n",
      "|                947|        Airbus A319||Boei...|\n",
      "|               1462|        Embraer 175||Boei...|\n",
      "|               1462|        Embraer 175||Boei...|\n",
      "|               1462|        Embraer 175||Airb...|\n",
      "|               1462|        Embraer 175 (Enha...|\n",
      "|               1571|        AIRBUS INDUSTRIE ...|\n",
      "|                947|              Boeing 737-800|\n",
      "|                956|        Canadian Regional...|\n",
      "|                956|        Canadair Regional...|\n",
      "|                956|        Airbus A319||Boei...|\n",
      "+-------------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# impute `segmentsEquipmentDescription` with mode\n",
    "\n",
    "mode_value = df_cleaned.groupBy(\"segmentsEquipmentDescription\").count()     .orderBy(\"count\", ascending=False).first()[0]\n",
    "df_cleaned = df_cleaned.fillna({\"segmentsEquipmentDescription\": mode_value})\n",
    "\n",
    "df_cleaned.select(\"totalTravelDistance\", \"segmentsEquipmentDescription\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd7a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:====================================================>(124 + 1) / 125]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing percentages per column:\n",
      "legId: 0.00%\n",
      "searchDate: 0.00%\n",
      "flightDate: 0.00%\n",
      "startingAirport: 0.00%\n",
      "destinationAirport: 0.00%\n",
      "fareBasisCode: 0.00%\n",
      "travelDuration: 0.00%\n",
      "elapsedDays: 0.00%\n",
      "isBasicEconomy: 0.00%\n",
      "isRefundable: 0.00%\n",
      "isNonStop: 0.00%\n",
      "baseFare: 0.00%\n",
      "totalFare: 0.00%\n",
      "seatsRemaining: 0.00%\n",
      "totalTravelDistance: 0.00%\n",
      "segmentsDepartureTimeEpochSeconds: 0.00%\n",
      "segmentsDepartureTimeRaw: 0.00%\n",
      "segmentsArrivalTimeEpochSeconds: 0.00%\n",
      "segmentsArrivalTimeRaw: 0.00%\n",
      "segmentsArrivalAirportCode: 0.00%\n",
      "segmentsDepartureAirportCode: 0.00%\n",
      "segmentsAirlineName: 0.00%\n",
      "segmentsAirlineCode: 0.00%\n",
      "segmentsEquipmentDescription: 0.00%\n",
      "segmentsDurationInSeconds: 0.00%\n",
      "segmentsDistance: 0.00%\n",
      "segmentsCabinCode: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calculate the percentage of missing values for each column\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "total_count = df_cleaned.count()\n",
    "missing_percentages = {\n",
    "    col: (df_cleaned.filter(F.col(col).isNull()).count() / total_count) * 100\n",
    "    for col in df_cleaned.columns\n",
    "}\n",
    "# print the missing percentages\n",
    "\n",
    "print(\"Missing percentages per column:\")\n",
    "for col, percent in missing_percentages.items():\n",
    "    print(f\"{col}: {percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833a830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 106:====================================================>(124 + 1) / 125]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in totalTravelDistance: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# obtain the median value for `totalTravelDistance`\n",
    "# impute missing values with the median\n",
    "\n",
    "median_totalTravelDistance = df_cleaned.approxQuantile(\"totalTravelDistance\", [0.5], 0.01)[0]\n",
    "df_cleaned = df_cleaned.fillna({\"totalTravelDistance\": median_totalTravelDistance})\n",
    "\n",
    "# check nulls in `totalTravelDistance`\n",
    "\n",
    "null_totalTravelDistance = df_cleaned.filter(df_cleaned.totalTravelDistance.isNull()).count()\n",
    "null_percentage = (null_totalTravelDistance / total_count) * 100\n",
    "print(f\"Percentage of null values in totalTravelDistance: {null_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81ee61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not in human-legible formats\n",
    "\n",
    "df_cleaned = df_cleaned.drop('segmentsDepartureTimeEpochSeconds', 'segmentsArrivalTimeEpochSeconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1027fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_data_path = \"gs://my-bigdatatech-project-jl/cleaned/Data_Cleaned.parquet\"\n",
    "df_cleaned.write.mode(\"overwrite\").parquet(cleaned_data_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
